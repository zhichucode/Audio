{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d9cb73-818b-44bb-8b14-ed5a2b10da36",
   "metadata": {},
   "source": [
    "## input audio by pyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b492857-5a2f-4195-9baa-6d37bbca9e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Use the PyAudio class to create a object named stream\n",
    "# Init\n",
    "stream = p.open(format=FORMAT,  # the format of sound\n",
    "                channels=CHANNELS, #sound channels\n",
    "                rate=RATE, # sampling_rate\n",
    "                input=True, \n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "# put the read data to \"frames\", Start recording\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e1f6b-f960-4ad9-b035-54e9f4c2e9b9",
   "metadata": {},
   "source": [
    "## input audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d3e63-db37-45f1-82b2-842d63d3bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Plot the live microphone signal(s) with matplotlib.\n",
    "\n",
    "Matplotlib and NumPy have to be installed.\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "import queue\n",
    "import sys\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "\n",
    "def int_or_str(text):\n",
    "    \"\"\"Helper function for argument parsing.\"\"\"\n",
    "    try:\n",
    "        return int(text)\n",
    "    except ValueError:\n",
    "        return text\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "parser.add_argument(\n",
    "    '-l', '--list-devices', action='store_true',\n",
    "    help='show list of audio devices and exit')\n",
    "args, remaining = parser.parse_known_args()\n",
    "if args.list_devices:\n",
    "    print(sd.query_devices())\n",
    "    parser.exit(0)\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=__doc__,\n",
    "    formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "    parents=[parser])\n",
    "parser.add_argument(\n",
    "    'channels', type=int, default=[1], nargs='*', metavar='CHANNEL',\n",
    "    help='input channels to plot (default: the first)')\n",
    "parser.add_argument(\n",
    "    '-d', '--device', type=int_or_str,\n",
    "    help='input device (numeric ID or substring)')\n",
    "parser.add_argument(\n",
    "    '-w', '--window', type=float, default=200, metavar='DURATION',\n",
    "    help='visible time slot (default: %(default)s ms)')\n",
    "parser.add_argument(\n",
    "    '-i', '--interval', type=float, default=30,\n",
    "    help='minimum time between plot updates (default: %(default)s ms)')\n",
    "parser.add_argument(\n",
    "    '-b', '--blocksize', type=int, help='block size (in samples)')\n",
    "parser.add_argument(\n",
    "    '-r', '--samplerate', type=float, help='sampling rate of audio device')\n",
    "parser.add_argument(\n",
    "    '-n', '--downsample', type=int, default=10, metavar='N',\n",
    "    help='display every Nth sample (default: %(default)s)')\n",
    "args = parser.parse_args(remaining)\n",
    "if any(c < 1 for c in args.channels):\n",
    "    parser.error('argument CHANNEL: must be >= 1')\n",
    "mapping = [c - 1 for c in args.channels]  # Channel numbers start with 1\n",
    "q = queue.Queue()\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"This is called (from a separate thread) for each audio block.\"\"\"\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    # Fancy indexing with mapping creates a (necessary!) copy:\n",
    "    q.put(indata[::args.downsample, mapping])\n",
    "\n",
    "\n",
    "def update_plot(frame):\n",
    "    \"\"\"This is called by matplotlib for each plot update.\n",
    "\n",
    "    Typically, audio callbacks happen more frequently than plot updates,\n",
    "    therefore the queue tends to contain multiple blocks of audio data.\n",
    "\n",
    "    \"\"\"\n",
    "    global plotdata\n",
    "    while True:\n",
    "        try:\n",
    "            data = q.get_nowait()\n",
    "        except queue.Empty:\n",
    "            break\n",
    "        shift = len(data)\n",
    "        plotdata = np.roll(plotdata, -shift, axis=0)\n",
    "        plotdata[-shift:, :] = data\n",
    "    for column, line in enumerate(lines):\n",
    "        line.set_ydata(plotdata[:, column])\n",
    "    return lines\n",
    "\n",
    "\n",
    "try:\n",
    "    if args.samplerate is None:\n",
    "        device_info = sd.query_devices(args.device, 'input')\n",
    "        args.samplerate = device_info['default_samplerate']\n",
    "\n",
    "    length = int(args.window * args.samplerate / (1000 * args.downsample))\n",
    "    plotdata = np.zeros((length, len(args.channels)))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    lines = ax.plot(plotdata)\n",
    "    if len(args.channels) > 1:\n",
    "        ax.legend(['channel {}'.format(c) for c in args.channels],\n",
    "                  loc='lower left', ncol=len(args.channels))\n",
    "    ax.axis((0, len(plotdata), -1, 1))\n",
    "    ax.set_yticks([0])\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.tick_params(bottom=False, top=False, labelbottom=False,\n",
    "                   right=False, left=False, labelleft=False)\n",
    "    fig.tight_layout(pad=0)\n",
    "\n",
    "    stream = sd.InputStream(\n",
    "        device=args.device, channels=max(args.channels),\n",
    "        samplerate=args.samplerate, callback=audio_callback)\n",
    "    ani = FuncAnimation(fig, update_plot, interval=args.interval, blit=True)\n",
    "    with stream:\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    parser.exit(type(e).__name__ + ': ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4f66d-3e3b-4e8b-801c-af9c58f8838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "rate = 48000\n",
    "chunk_size = 1024\n",
    "#chunk_size = 1024\n",
    "\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paFloat32,\n",
    "                channels=1,\n",
    "                rate=rate,\n",
    "                input=True,\n",
    "                input_device_index=1,\n",
    "                frames_per_buffer=chunk_size)\n",
    "\n",
    "\n",
    "frames = []\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "do_melspec = librosa.feature.melspectrogram\n",
    "pwr_to_db = librosa.core.power_to_db\n",
    "\n",
    "while True:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    data = stream.read(chunk_size, exception_on_overflow = False)\n",
    "    data = np.fromstring(data, dtype=np.float32)\n",
    "    melspec = do_melspec(y=data, sr=rate, n_mels=128, fmax=4000)\n",
    "    norm_melspec = pwr_to_db(melspec, ref=np.max)\n",
    "    frames.append(norm_melspec)\n",
    "    if len(frames) == 20:\n",
    "        stack = np.hstack(frames)        \n",
    "        librosa.display.specshow(stack, y_axis='mel', fmax=4000, x_axis='time')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Mel spectrogram')\n",
    "        plt.draw()\n",
    "        plt.pause(0.0001)\n",
    "        plt.clf()\n",
    "        #break\n",
    "        frames.pop(0)\n",
    "    t = time.time() - start\n",
    "\n",
    "    print(1 / t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9143d0c-c342-416a-b082-0aa352f03351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
